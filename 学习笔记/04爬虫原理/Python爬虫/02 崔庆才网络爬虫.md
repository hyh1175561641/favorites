

[TOC]



# 前言

名言摘取：

人工智能的进步离不开数据和算法的结合





# 第一章 开发环境配置

**学习教程**

[Awesome Python](https://awesome-python.com)

[github.com/vinta/awesome-python](https://github.com/vinta/awesome-python)

[上一行的中文版](https://github.com/jobbole/awesome-python-cn)



**Python安装**

Anaconda



**请求库**

requests

Selenium

ChromeDriver

GeckoDriver

PhantomJS

aiohttp

**解析库**

lxml

Beautiful Soup

pyquery

tesserocr

**数据库**

MySQL

MongoDB

Redis

**存储库**

PyMysql

PyMongo

Redis-py

redisDump

**Web库**

Flask

Tornado

**App爬取相关库**

Charles

mitmproxy

Appium

**爬虫框架**

pyspider

Scrapy

scrapy-splash

Scrapy-Redis

**部署相关库**

Docker

Scrapyd

Scrapyd-Client

Scrapyd API

Scrapyrt

Gerapy



# 第二章 爬虫基础

HTTP基本原理 URI和URL 超文本 HTTP和HTTPS HTTP请求过程 请求和响应

见通信的HTTP文档



网页的组成，结构，节点树及节点间的关系，选择器

见前端js文档



爬虫的基本原理

见通信的HTTP文档



会话和Cookies，静态和动态，无状态HTTP

见通信的HTTP文档



代理的基本原理

见通信的HTTP文档



# 第三章 基本库的使用

urllib



requests





正则表达式



# 第四章 解析库的使用





# 第五章 数据存储



# 第六章 Ajax数据爬取



# 第七章 动态渲染页面爬取





# 第八章 验证码的识别





# 第九章 代理的使用





# 第十章 模拟登陆



# 第十一章 App的爬取



# 第十二章 pyspider框架的使用



# 第十三章 Scrapy框架的使用



# 第十四章 分布式爬虫



# 第十五章 分布式爬虫的部署























































# 链接

[崔庆才个人站点](https://cuiqingcai.com)

[本书站点](https://cuiqingcai.com/5052.html)

[崔庆才爬虫视频](https://www.bilibili.com/video/av52151245/)

[代码实例](https://github.com/Python3WebSpider)

QQ群：733596899